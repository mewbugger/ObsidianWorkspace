#### Map
##### HashMap
- **线程是否安全**：线程不安全
- **效率**：由于线程不安全，所以效率高
- **对`null`的支持**：可以存储为`null`的`key`和`value`，但是null作为键只能有一个，`null`作为`value`可以有多个
- **初始容量大小和每次扩容大小**：
1. 创建的时候没有指定初始容量，默认初始化大小为16。之后每次扩容，容量变为原来的2倍。
2. 创建的时候如果给定了容量初始值，扩容的时候会将容量扩充为2的幂次方大小。即**总是使用2的幂作为哈希表的大小**。
- **底层数据结构**：JDK1.8 以后的 `HashMap` 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）时，将链表转化为红黑树（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树），以减少搜索时间
`HashMap`中带有**初始容量的构造函数**：
``` java
public HashMap(int initialCapacity, float loadFactor) {
        if (initialCapacity < 0)
            throw new IllegalArgumentException("Illegal initial capacity: " +                          initialCapacity);
        if (initialCapacity > MAXIMUM_CAPACITY)
            initialCapacity = MAXIMUM_CAPACITY;
        if (loadFactor <= 0 || Float.isNaN(loadFactor))
            throw new IllegalArgumentException("Illegal load factor: " +
                                              loadFactor);
        this.loadFactor = loadFactor;
        this.threshold = tableSizeFor(initialCapacity);
    }
     public HashMap(int initialCapacity) {
        this(initialCapacity, DEFAULT_LOAD_FACTOR);
    }
```
下面这个方法保证了`HashMap`总是**使用2的幂作为哈希表的大小**，**找到大于等于cap的最小的2的幂**
``` java
/**

     * Returns a power of two size for the given target capacity.

     */

    static final int tableSizeFor(int cap) {
	    //将`cap`减1，这是为了处理`cap`本身就是2的幂的情况。例如，如果`cap`是8（即2的3次方），我们希望得到的结果仍然是8，而不是16（即2的4次方）。
        int n = cap - 1;
        //将`n`和`n`右移1位的结果进行按位或操作。这会将`n`的最高位右边的1位变为1。
        n |= n >>> 1;
        //这几行代码的作用和上面的类似，只是每次右移的位数在增加，分别是4位、8位和16位。这些操作会将`n`的最高位右边的所有位都变为1。
        n |= n >>> 2;
        n |= n >>> 4;
        n |= n >>> 8;
        n |= n >>> 16;
        //最后，如果`n`小于0（这在Java中意味着`n`的最高位是1，即`n`是负数），则返回1；如果`n`大于或等于`MAXIMUM_CAPACITY`（这是HashMap的最大容量），则返回`MAXIMUM_CAPACITY`；否则，返回`n + 1`。`n + 1`就是大于或等于`cap`的最小2的幂。
        return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1;

    }
```
###### HashMap的底层实现
**JDK1.8之前**
`HashMap`底层是数组和链表结合在一起使用，也就是**链表散列**。`HashMap` 通过 `key `的 `hashcode` 经过**扰动函数**（即`HashMap`的`hash`方法，防止一些实现比较差的`hashCode()`方法，换句话说就是使用扰动函数之后可以减少碰撞）处理过后得到` hash `值，然后通过 `(n - 1) & hash` 判断当前元素存放的位置（这里的 n 指的是数组的长度），如果当前位置存在元素的话，就判断该元素与要存入的元素的 `hash` 值以及 `key `是否相同，如果相同的话，直接覆盖，不相同就通过拉链法解决冲突。
**JDK1.8之后**
在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为 8）（将链表转换成红黑树前会判断，如果当前数组的长度小于 64，那么会选择先进行数组扩容，而不是转换为红黑树）时，将链表转化为红黑树，以减少搜索时间。

###### 为什么长度是2的幂次方
HashMap的长度选择为2的幂次方，主要是为了优化HashMap的键值对（key-value pair）的存储和查找效率。
在HashMap中，当我们插入一个键值对时，会使用键（key）的哈希值（hash value）和HashMap的长度进行一些计算，得到这个键值对在HashMap内部数组中的存储位置。这个计算过程通常被称为“散列”（hashing）。
如果HashMap的长度是2的幂次方，那么我们可以使用一种非常高效的方式来进行这个计算：只需要将键的哈希值和HashMap的长度减1进行按位与操作（bitwise AND operation）。这个操作在计算机中可以非常快速地完成。
举个例子，假设我们有一个键的哈希值是`h`，并且HashMap的长度是16（即2的4次方）。那么，我们可以通过计算`h & (16 - 1)`来得到这个键值对在HashMap内部数组中的存储位置。这个计算过程非常快速，而且可以保证得到的结果总是在0到15之间，正好对应了HashMap内部数组的所有可能位置。
###### HashMap多线程操作导致死循环问题
**JDK1.7 及之前版本**的 `HashMap` 在多线程环境下扩容操作可能存在死循环问题，这是由于当一个桶位中有多个元素需要进行扩容时，多个线程同时对链表进行操作，头插法可能会导致链表中的节点指向错误的位置，从而形成一个环形链表，进而使得查询元素的操作陷入死循环无法结束。
**解析**：
假设我们有一个HashMap，它的一个桶位中有一个链表，链表的节点是A->B->C->null。现在，我们需要对这个HashMap进行扩容。
在单线程环境下，扩容过程会将链表中的每个节点取出，然后根据新的桶位数量重新计算它们的位置，并使用头插法将它们插入到新的桶位中。所以，链表A->B->C->null可能会变成C->B->A->null。
但是，在多线程环境下，如果两个线程同时对这个链表进行操作，就可能会出现问题。例如，线程1取出节点A并计算出它的新位置，然后线程2也取出节点A并计算出它的新位置。这时，线程1将节点A插入到新的位置，然后线程2也将节点A插入到新的位置。由于使用了头插法，所以线程2实际上将节点A插入到了它自己之前，形成了一个环形链表A->A->…。这就是死循环问题的来源。
**解决方案**：
为了解决这个问题，**JDK1.8 版本**的 HashMap 采用了尾插法而不是头插法来避免链表倒置，使得插入的节点永远都是放在链表的末尾，避免了链表中的环形结构。但是还是不建议在多线程下使用 `HashMap`，因为多线程下使用 `HashMap` 还是会存在数据覆盖的问题。并发环境下，推荐使用 `ConcurrentHashMap` 。

###### HashMap为什么线程不安全
举个例子：
- 两个线程 1,2 同时进行 put 操作，并且发生了哈希冲突（hash 函数计算出的插入下标是相同的）。
- 不同的线程可能在不同的时间片获得 CPU 执行的机会，当前线程 1 执行完哈希冲突判断后，由于时间片耗尽挂起。线程 2 先完成了插入操作。
- 随后，线程 1 获得时间片，由于之前已经进行过 hash 碰撞的判断，所有此时会直接进行插入，这就导致线程 2 插入的数据被线程 1 覆盖了。

还有一种情况是这两个线程同时 `put` 操作导致 `size` 的值不正确，进而导致数据覆盖的问题：
1. 线程 1 执行 `if(++size > threshold)` 判断时，假设获得 `size` 的值为 10，由于时间片耗尽挂起。
2. 线程 2 也执行 `if(++size > threshold)` 判断，获得 `size` 的值也为 10，并将元素插入到该桶位中，并将 `size` 的值更新为 11。
3. 随后，线程 1 获得时间片，它也将元素放入桶位中，并将 size 的值更新为 11。
4. 线程 1、2 都执行了一次 `put` 操作，但是 `size` 的值只增加了 1，也就导致实际上只有一个元素被添加到了 `HashMap` 中。

##### ConcurrentHashMap
- **底层数据结构**：`JDK1.8`采用的数据结构跟`HashMap1.8`一样，是数组+链表/红黑二叉树。
- **实现线程安全的方式**：`JDK1.8`的时候，用`Node`数组+链表+红黑树的数据结构来实现，并发控制使用`synchronized`和`CAS`来操作。

###### ConcurrentHashMap线程安全的具体实现方式/底层具体实现 （[CAS](../JUC/原子类.md#CAS)）
**JDK1.8之后**：采用 `Node + CAS + synchronized` 来保证并发安全。数据结构跟 `HashMap` 1.8 的结构类似，数组+链表/红黑二叉树。Java 8 在链表长度超过一定阈值（8）时将链表（寻址时间复杂度为 O(N)）转换为红黑树（寻址时间复杂度为 O(log(N))）。
Java 8 中，锁粒度更细，`synchronized` 只锁定当前链表或红黑二叉树的首节点，这样只要 hash 不冲突，就不会产生并发，就不会影响其他 Node 的读写，效率大幅提升。
**对Node数组进行循环遍历**
1. 如果table为null或者长度为0，则进行初始化
2. 如果哈希槽为空，则通过CAS操作尝试插入新节点（**CAS**）
3. 如果哈希槽处已经有节点，且hash值为MOVED，则说明正在进行扩容
4. 如果哈希槽处已经有节点，且hash值不为MOVED，则进行链表/红黑树插入，**这里需要对节点加锁synchronized**

##### HashTable
线程安全，对每一个方法都加上synchronized锁，参考方法锁（[synchronized关键字](../JUC/synchronized关键字.md)），效率极低，**方法锁默认锁的是对象，所以当一个线程put的时候，别的线程既不能put也不能get。**

